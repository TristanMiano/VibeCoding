#!/usr/bin/env python3
"""
generate_project_overview.py

Usage examples:

  # full overview, no skipping
  python generate_project_overview.py

  # short mode: only signatures/docstrings in supported languages
  python generate_project_overview.py --short

  # skip everything under data/ and build/, but re-include data/important/
  python generate_project_overview.py \
      --exclude data/** build/** \
      --include data/important/**

  # you can mix --short with --exclude/--include freely
"""

import os
import sys
import fnmatch
import argparse
from pathlib import Path

from tree_sitter import Language, Parser
from tree_sitter_language_pack import get_language, get_parser
import ast  # still used for Python import parsing

# Map file extensions to tree-sitter language names (must be compiled into the shared library)
EXT_LANG_MAP = {
    '.py': 'python',
    '.js': 'javascript',
    '.ts': 'typescript',
    '.java': 'java',
    '.c': 'c',
    '.cpp': 'cpp',
    '.go': 'go',
    '.rb': 'ruby',
    '.php': 'php',
    '.swift': 'swift',
    '.kt': 'kotlin',
    '.scala': 'scala',
    '.rs': 'rust',
}

# A naive list of known standard library modules we skip from "requirements".
STANDARD_LIBS = {
    "abc", "argparse", "ast", "asyncio", "base64", "binascii", "bisect", "builtins", "calendar",
    "collections", "concurrent", "contextlib", "copy", "csv", "ctypes", "datetime", "decimal",
    "difflib", "dis", "distutils", "email", "enum", "errno", "faulthandler", "filecmp", "fileinput",
    "fnmatch", "fractions", "functools", "gc", "getopt", "getpass", "gettext", "glob", "gzip", "hashlib",
    "heapq", "hmac", "http", "imaplib", "imp", "importlib", "inspect", "io", "ipaddress", "itertools",
    "json", "logging", "lzma", "math", "multiprocessing", "numbers", "operator", "os", "pathlib",
    "pickle", "platform", "plistlib", "pprint", "queue", "random", "re", "runpy", "sched", "secrets",
    "select", "shlex", "shell", "shutil", "signal", "site", "smtp", "smtplib", "socket", "socketserver",
    "sqlite3", "ssl", "stat", "statistics", "string", "struct", "subprocess", "sys", "tempfile", "termios",
    "textwrap", "threading", "time", "timeit", "tkinter", "traceback", "types", "typing", "unittest",
    "urllib", "uuid", "venv", "warnings", "wave", "weakref", "webbrowser", "xml", "xmlrpc", "zipfile", "zipimport"
}

PROMPT_TEXT = """PROMPT FOR AI MODEL:

You are about to read a detailed overview of a software project. Please read 
Everything in the following text and act as a helpful software engineering assistant. This overview itself is generated by one of the files which will be described below.

At the end of the overview, there will be a list of next steps for implementation. Please tailor your response for these steps. Generally, if more than one step is listed, focus on the first one only in your first response. The user will probably request the subsequent steps later.

Do not add unnecessary complexity. Do not assume the user will infer the proper steps to take if you leave some out. Be very explicit. If you generate code, generate the entire file fully working. You may generate code snippets if the user asks for those. If you do, please explain exactly where to put them.

If you can't find any next steps for the project listed at the bottom of the file, please do your best to look for mistakes, errors, discrepancies, or ways to clean up and refine the project, and decide yourself what should be considered high priority, and include that in your first response.

--------------------------------------------------------------------------------
"""


def is_text_file(file_path: Path) -> bool:
    text_extensions = set(EXT_LANG_MAP.keys()) | {'.txt', '.md', '.rst', '.html', '.css', '.xml', '.yaml', '.yml', '.sh', '.bat', '.sql'}
    return file_path.suffix.lower() in text_extensions


def get_file_type(file_path: Path) -> str:
    return file_path.suffix.lower() if file_path.suffix else 'No Extension'


def parse_imports_from_python(file_content: str) -> set[str]:
    try:
        tree = ast.parse(file_content)
    except SyntaxError:
        return set()
    mods = set()
    for node in ast.walk(tree):
        if isinstance(node, ast.Import):
            for alias in node.names:
                mods.add(alias.name.split('.')[0])
        elif isinstance(node, ast.ImportFrom) and node.module:
            mods.add(node.module.split('.')[0])
    return mods


def is_standard_library(module_name: str) -> bool:
    return module_name in STANDARD_LIBS


def extract_tree_functions(file_bytes: bytes, ext: str, parsers: dict) -> str:
    """
    Parse the file bytes with tree-sitter and extract function/class definitions plus docstrings or preceding comments.
    """
    lang_name = EXT_LANG_MAP.get(ext)
    parser = parsers.get(lang_name)
    if not parser:
        return ''
    tree = parser.parse(file_bytes)
    root = tree.root_node
    lines: list[str] = []

    # Module-level docstring or leading comments
    if lang_name == 'python':
        for child in root.children:
            if child.type == 'expression_statement' and child.children and child.children[0].type == 'string':
                module_doc = child.children[0].text.decode('utf-8')
                lines.append(f'Module Docstring:\n{module_doc}\n')
                break
    else:
        leading_comments = []
        for child in root.children:
            if child.type == 'comment':
                leading_comments.append(child.text.decode('utf-8'))
            else:
                break
        if leading_comments:
            lines.append('Module Comments:')
            lines += leading_comments
            lines.append('')

    # Recursive traversal
    def traverse(node):
        yield node
        for c in node.children:
            yield from traverse(c)

    func_nodes = {'function_definition', 'function_declaration', 'method_definition', 'method_declaration', 'arrow_function', 'function'}
    class_nodes = {'class_definition', 'class_declaration', 'struct_specifier'}

    for node in traverse(root):
        if node.type in func_nodes or node.type in class_nodes:
            # Get name
            name = '<anonymous>'
            for c in node.children:
                if c.type in ('identifier', 'name') or c.type.endswith('name'):
                    name = c.text.decode('utf-8')
                    break
            kind = 'def' if node.type in func_nodes else 'class'
            lines.append(f'{kind} {name}()')
            # Extract doc
            doc = None
            if lang_name == 'python':
                # look for first string literal in suite
                for c in node.children:
                    if c.type == 'suite':
                        for stmt in c.children:
                            if stmt.type == 'expression_statement' and stmt.children and stmt.children[0].type == 'string':
                                doc = stmt.children[0].text.decode('utf-8')
                                break
                        break
            else:
                # find comment immediately preceding node
                comments = [n for n in traverse(root) if n.type == 'comment' and n.end_byte < node.start_byte]
                if comments:
                    doc = comments[-1].text.decode('utf-8')
            if doc:
                for l in doc.splitlines():
                    lines.append('    ' + l)
            lines.append('')
    return '\n'.join(lines)


def is_excluded(
    rel_path: str,
    exclude_patterns: list[str],
    include_patterns: list[str]
) -> bool:
    # Include always wins
    for pat in include_patterns:
        if fnmatch.fnmatch(rel_path, pat):
            return False
    # Then exclude
    for pat in exclude_patterns:
        if fnmatch.fnmatch(rel_path, pat):
            return True
    return False


def traverse_directory(
    root_path: Path,
    short_version: bool = False,
    exclude_patterns: list[str] = None,
    include_patterns: list[str] = None,
    parsers: dict = None
):
    exclude_patterns = exclude_patterns or []
    include_patterns = include_patterns or []

    directory_structure: list[str] = []
    relevant_contents: list[str] = []
    third_party_libraries: set[str] = set()

    for dirpath, dirnames, filenames in os.walk(root_path):
        dirnames[:] = [d for d in dirnames if not d.startswith('.')]
        rel_dir = Path(dirpath).relative_to(root_path).as_posix() or '.'
        if is_excluded(rel_dir, exclude_patterns, include_patterns):
            continue
        directory_structure.append(f'Directory: {rel_dir}')
        dirnames[:] = [d for d in dirnames if not is_excluded(f"{rel_dir}/{d}", exclude_patterns, include_patterns)]
        for fn in filenames:
            if fn.startswith('.'):
                continue
            rel_file = fn if rel_dir == '.' else f"{rel_dir}/{fn}"
            if is_excluded(rel_file, exclude_patterns, include_patterns):
                continue
            p = Path(dirpath) / fn
            directory_structure.append(f'  File: {fn} | Type: {get_file_type(p)}')

            if is_text_file(p):
                try:
                    ext = p.suffix.lower()
                    # handle imports for Python
                    if ext == '.py':
                        content_py = p.read_text(encoding='utf-8')
                        imports = parse_imports_from_python(content_py)
                        for lib in imports:
                            if not is_standard_library(lib):
                                third_party_libraries.add(lib)
                    # short mode: extract via tree-sitter if supported
                    if short_version and ext in EXT_LANG_MAP:
                        content_bytes = p.read_bytes()
                        snippet = extract_tree_functions(content_bytes, ext, parsers)
                        relevant_contents.append(f"\n=== Functions & Docstrings in {rel_file} ===\n{snippet}")
                    else:
                        content = p.read_text(encoding='utf-8')
                        relevant_contents.append(f"\n=== Content of {rel_file} ===\n{content}")
                except Exception as e:
                    print(f"Warning: could not read {p}: {e}", file=sys.stderr)
    return directory_structure, relevant_contents, third_party_libraries


def main():
    parser = argparse.ArgumentParser(description="Generate a project overview.")
    parser.add_argument(
        "--short", action="store_true", default=False,
        help="Only include function signatures & docstrings for supported languages."
    )
    parser.add_argument(
        "-e", "--exclude", nargs="*", default=[], help="Glob patterns of files/dirs to skip entirely."
    )
    parser.add_argument(
        "-i", "--include", nargs="*", default=[], help="Glob patterns to force-include (overrides exclude)."
    )
    
    args = parser.parse_args()

    # Initialize parsers for each language
    # build a map of all the parsers you need
    parsers: dict[str, any] = {}
    for ext, lang_name in EXT_LANG_MAP.items():
        try:
            # get_parser() returns a Parser() already set up with that language
            parsers[lang_name] = get_parser(lang_name)
        except KeyError:
            # language wasn’t included in the wheel (very rare)
            pass

    root = Path.cwd().resolve()
    print(f"Traversing directory: {root}")

    dirs, contents, libs = traverse_directory(
        root_path=root,
        short_version=args.short,
        exclude_patterns=args.exclude,
        include_patterns=args.include,
        parsers=parsers
    )

    overview_path = root / "project_overview.txt"
    with overview_path.open('w', encoding='utf-8') as f:
        f.write(PROMPT_TEXT)
        f.write("\n=== Directory Structure ===\n")
        f.write("\n".join(dirs))
        f.write("\n\n=== Consolidated Documentation ===\n")
        f.write("\n".join(contents))
        f.write("\n\n" + "-"*80)
    print(f"Written overview to {overview_path}")

    req_path = root / "requirements_autogenerated.txt"
    with req_path.open('w', encoding='utf-8') as f:
        for lib in sorted(libs):
            f.write(lib.lower() + "\n")
    print(f"Written requirements to {req_path}")

if __name__ == "__main__":
    main()
